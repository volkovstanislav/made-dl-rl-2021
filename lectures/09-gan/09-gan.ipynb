{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import scipy.integrate as integrate\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import statsmodels.api as sm\n",
    "from matplotlib.colors import LogNorm\n",
    "import pickle\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "\n",
    "import cProfile\n",
    "from datetime import datetime\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "palette = sns.color_palette()\n",
    "figsize = (15,8)\n",
    "legend_fontsize = 16\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif'})\n",
    "rc('text', usetex=True)\n",
    "rc('text.latex',preamble=r'\\usepackage[utf8]{inputenc}')\n",
    "rc('text.latex',preamble=r'\\usepackage[russian]{babel}')\n",
    "rc('figure', **{'dpi': 300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN: сначала наивно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## загружаем MNIST\n",
    "image_size = 28\n",
    "image_shape = (1, image_size, image_size)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "batch_size = 64\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(image_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=100):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(noise_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(image_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *image_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(image_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "generator = Generator(noise_dim=noise_dim)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Оптимизаторы и их параметры\n",
    "lr, beta1, beta2 = 0.0002, 0.5, 0.999\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, do_epoch=None, num_epochs=10, sample_dir=\"data/images/gan\", generate_every=100):\n",
    "    d_losses, g_losses = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (imgs, _) in enumerate(dataloader):\n",
    "            gen_imgs, d_loss, g_loss = do_epoch(imgs, i)\n",
    "            if d_loss is not None and g_loss is not None:\n",
    "                d_losses.append(d_loss.item())\n",
    "                g_losses.append(g_loss.item())\n",
    "            batches_done = epoch * len(dataloader) + i\n",
    "            if batches_done % generate_every == 0:\n",
    "                print(\"\\t...epoch %d/%d\\tbatch %d/%d\\tD loss: %.6f\\tG loss: %.6f\" % \\\n",
    "                      (epoch, num_epochs, i, len(dataloader), d_losses[-1], g_losses[-1]))\n",
    "                save_image(gen_imgs.data[:25], \"%s/%05d.png\" % (sample_dir, batches_done), nrow=5, normalize=True)\n",
    "    return d_losses, g_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch_gan(imgs, i):\n",
    "    # целевые переменные (0-1) для настоящих и фейковых картинок\n",
    "    valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "    fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "    # вход\n",
    "    real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "    # обучаем генератор\n",
    "    optimizer_G.zero_grad()\n",
    "\n",
    "    # порождаем шум\n",
    "    z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], noise_dim))))\n",
    "\n",
    "    # порождаем фейковые картинки\n",
    "    gen_imgs = generator(z)\n",
    "\n",
    "    # а вот и adversarial loss для генератора\n",
    "    g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    # А теперь обучаем дискриминатор\n",
    "    optimizer_D.zero_grad()\n",
    "    # Функции потерь на настоящих и фейковых картинках\n",
    "    real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "    fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "    d_loss = (real_loss + fake_loss) / 2\n",
    "    d_loss.backward()\n",
    "    optimizer_D.step()\n",
    "    return gen_imgs, d_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses, g_losses = train(dataloader, do_epoch_gan, num_epochs=20, sample_dir=\"data/images/test\", generate_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(d_losses, g_losses):\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    n_epochs = len(d_losses) - 1\n",
    "    x_train = np.linspace(0, n_epochs, len(d_losses))\n",
    "    x_test = np.arange(n_epochs + 1)\n",
    "\n",
    "    ax.plot(x_train, d_losses, label='Ошибка дискриминатора')\n",
    "    ax.plot(x_test, g_losses, label='Ошибка генератора')\n",
    "    ax.legend()\n",
    "    plt.xlabel('Эпоха обучения')\n",
    "    plt.ylabel('Ошибка')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(d_losses, g_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Url](results_gan.gif \"GAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSGANSimpleDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSGANSimpleDiscriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(image_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1), ## для least squares сигмоид не нужен\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "\n",
    "## по сути это единственная разница, дальше можно то же самое сделать\n",
    "ls_advloss = torch.nn.MSELoss()\n",
    "\n",
    "ls_G = Generator(noise_dim=noise_dim)\n",
    "ls_D = LSGANSimpleDiscriminator()\n",
    "\n",
    "if cuda:\n",
    "    ls_G.cuda()\n",
    "    ls_D.cuda()\n",
    "    ls_advloss.cuda()\n",
    "\n",
    "## Оптимизаторы и их параметры\n",
    "lr, beta1, beta2 = 0.0002, 0.5, 0.999\n",
    "ls_opt_G = torch.optim.Adam(ls_G.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "ls_opt_D = torch.optim.Adam(ls_D.parameters(), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch_lsgan(imgs, i):\n",
    "    # целевые переменные (0-1) для настоящих и фейковых картинок\n",
    "    valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "    # вход\n",
    "    real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "    # обучаем генератор\n",
    "    ls_opt_G.zero_grad()\n",
    "\n",
    "    # порождаем шум\n",
    "    z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], noise_dim))))\n",
    "\n",
    "    # порождаем фейковые картинки\n",
    "    gen_imgs = ls_G(z)\n",
    "    \n",
    "    # а вот и adversarial loss для генератора\n",
    "    g_loss = ls_advloss(ls_D(gen_imgs), valid)\n",
    "\n",
    "    g_loss.backward()\n",
    "    ls_opt_G.step()\n",
    "\n",
    "    # А теперь обучаем дискриминатор\n",
    "    ls_opt_D.zero_grad()\n",
    "    # Функции потерь на настоящих и фейковых картинках\n",
    "    real_loss = ls_advloss(ls_D(real_imgs), valid)\n",
    "    fake_loss = ls_advloss(ls_D(gen_imgs.detach()), fake)\n",
    "    d_loss = (real_loss + fake_loss) / 2\n",
    "    d_loss.backward()\n",
    "    ls_opt_D.step()\n",
    "    return gen_imgs, d_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_losses, g_losses = train(dataloader, do_epoch_lsgan, num_epochs=50, sample_dir=\"data/images/test\", generate_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(d_losses, g_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LSGAN](results_lsgan_simple.gif \"Simple LSGAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSGANGenerator(nn.Module):\n",
    "    def __init__(self, noise_dim=100, num_channels=1):\n",
    "        super(LSGANGenerator, self).__init__()\n",
    "\n",
    "        self.init_size = image_size // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(noise_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, num_channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSGANDiscriminator(nn.Module):\n",
    "    def __init__(self, num_channels=1):\n",
    "        super(LSGANDiscriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(num_channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # Ширина и высота полученной карты признаков\n",
    "        ds_size = image_size\n",
    "        for _ in range(4): # четыре слоя\n",
    "            ds_size = math.ceil(ds_size / 2.)\n",
    "        self.adv_layer = nn.Linear(128 * (ds_size ** 2), 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_advloss = torch.nn.MSELoss()\n",
    "ls_G = LSGANGenerator()\n",
    "ls_D = LSGANDiscriminator()\n",
    "\n",
    "if cuda:\n",
    "    ls_G.cuda()\n",
    "    ls_D.cuda()\n",
    "    ls_advloss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Оптимизаторы и их параметры\n",
    "lr, beta1, beta2 = 0.0002, 0.5, 0.999\n",
    "ls_opt_G = torch.optim.Adam(ls_G.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "ls_opt_D = torch.optim.Adam(ls_D.parameters(), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d_losses, g_losses = train(dataloader, do_epoch_lsgan, num_epochs=50, sample_dir=\"data/images/test\", generate_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(d_losses, g_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LSGAN](results_lsgan.gif \"Convolutional LSGAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wassershtein GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "\n",
    "w_G = Generator(noise_dim=noise_dim)\n",
    "## для Wassershtein GAN тоже не нужен сигмоид\n",
    "w_D = LSGANSimpleDiscriminator()\n",
    "\n",
    "if cuda:\n",
    "    w_G.cuda()\n",
    "    w_D.cuda()\n",
    "\n",
    "## Оптимизаторы и их параметры\n",
    "lr, beta1, beta2 = 0.0002, 0.5, 0.999\n",
    "w_opt_G = torch.optim.Adam(w_G.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "# w_opt_D = torch.optim.Adam(w_D.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "w_opt_D = torch.optim.RMSprop(w_D.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch_wgan(imgs, i, n_critic=5, d_clip=0.01):\n",
    "    real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "    w_opt_D.zero_grad()\n",
    "\n",
    "    # Sample noise as generator input\n",
    "    z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], noise_dim))))\n",
    "\n",
    "    # Generate a batch of images\n",
    "    fake_imgs = w_G(z).detach()\n",
    "    \n",
    "    # Adversarial loss для Wassershtein GAN\n",
    "    loss_D = -torch.mean(w_D(real_imgs)) + torch.mean(w_D(fake_imgs))\n",
    "    loss_D.backward()\n",
    "    w_opt_D.step()\n",
    "\n",
    "    # Clip weights of discriminator\n",
    "    for p in discriminator.parameters():\n",
    "        p.data.clamp_(-d_clip, d_clip)\n",
    "\n",
    "    loss_G = None\n",
    "    # Train the generator every n_critic iterations\n",
    "    if i % n_critic == 0:\n",
    "        w_opt_G.zero_grad()\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = w_G(z)\n",
    "        # Adversarial loss\n",
    "        loss_G = -torch.mean(w_D(gen_imgs))\n",
    "        loss_G.backward()\n",
    "        w_opt_G.step()\n",
    "    \n",
    "    return fake_imgs, loss_D, loss_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_losses, g_losses = train(dataloader, do_epoch_wgan, num_epochs=50, sample_dir=\"data/images/test\", generate_every=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![WGAN](results_wgan.gif \"WGAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    # Случайные интерполяции между настоящими и фейковыми примерами\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "\n",
    "w_G = Generator(noise_dim=noise_dim)\n",
    "## для Wassershtein GAN тоже не нужен сигмоид\n",
    "w_D = LSGANSimpleDiscriminator()\n",
    "\n",
    "if cuda:\n",
    "    w_G.cuda()\n",
    "    w_D.cuda()\n",
    "\n",
    "## Оптимизаторы и их параметры\n",
    "lr, beta1, beta2 = 0.0002, 0.5, 0.999\n",
    "w_opt_G = torch.optim.Adam(w_G.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "# w_opt_D = torch.optim.Adam(w_D.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "w_opt_D = torch.optim.RMSprop(w_D.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch_wgan_gp(imgs, i, n_critic=5, d_clip=0.01, lambda_gp=10):\n",
    "    real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "    w_opt_D.zero_grad()\n",
    "\n",
    "    # Sample noise as generator input\n",
    "    z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], noise_dim))))\n",
    "\n",
    "    # Generate a batch of images\n",
    "    fake_imgs = w_G(z).detach()\n",
    "    \n",
    "    real_validity = w_D(real_imgs)\n",
    "    fake_validity = w_D(fake_imgs)\n",
    "    \n",
    "    # вычисляем GP\n",
    "    gradient_penalty = compute_gradient_penalty(w_D, real_imgs.data, fake_imgs.data)\n",
    "    \n",
    "    # Adversarial loss для Wassershtein GAN\n",
    "    d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
    "    d_loss.backward()\n",
    "    w_opt_D.step()\n",
    "\n",
    "    loss_G = None\n",
    "    # Train the generator every n_critic iterations\n",
    "    if i % n_critic == 0:\n",
    "        w_opt_G.zero_grad()\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = w_G(z)\n",
    "        # Adversarial loss\n",
    "        g_loss = -torch.mean(w_D(gen_imgs))\n",
    "        g_loss.backward()\n",
    "        w_opt_G.step()\n",
    "    \n",
    "    return fake_imgs, d_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_losses, g_losses = train(dataloader, do_epoch_wgan, num_epochs=50, sample_dir=\"data/images/test\", generate_every=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![WGAN with gradient penalty](results_wgan_gp.gif \"WGAN with gradient penalty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
