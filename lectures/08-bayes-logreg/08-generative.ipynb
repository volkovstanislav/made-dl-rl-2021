{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import scipy.integrate as integrate\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import statsmodels.api as sm\n",
    "from matplotlib.colors import LogNorm\n",
    "import pickle\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "\n",
    "import cProfile\n",
    "from datetime import datetime\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "palette = sns.color_palette()\n",
    "figsize = (15,8)\n",
    "legend_fontsize = 16\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif'})\n",
    "rc('text', usetex=True)\n",
    "rc('text.latex',preamble=r'\\usepackage[utf8]{inputenc}')\n",
    "rc('text.latex',preamble=r'\\usepackage[russian]{babel}')\n",
    "rc('figure', **{'dpi': 300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, d):\n",
    "  one_hot = torch.FloatTensor(labels.shape[0], d).cuda()\n",
    "  one_hot.zero_()\n",
    "  one_hot.scatter_(1, labels.unsqueeze(1), 1)\n",
    "  return one_hot\n",
    "\n",
    "# https://github.com/karpathy/pytorch-made\n",
    "class MaskedLinear(nn.Linear):\n",
    "  def __init__(self, in_features, out_features, bias=True):\n",
    "    super().__init__(in_features, out_features, bias)\n",
    "    self.register_buffer('mask', torch.ones(out_features, in_features))\n",
    "\n",
    "  def set_mask(self, mask):\n",
    "    self.mask.data.copy_(torch.from_numpy(mask.astype(np.uint8).T))\n",
    "\n",
    "  def forward(self, input):\n",
    "    return F.linear(input, self.mask * self.weight, self.bias)\n",
    "\n",
    "class MADE(nn.Module):\n",
    "  def __init__(self, input_shape, d, hidden_size=[512, 512, 512], \n",
    "               ordering=None, one_hot_input=False):\n",
    "    super().__init__()\n",
    "    self.input_shape = input_shape\n",
    "    self.nin = np.prod(input_shape)\n",
    "    self.nout = self.nin * d\n",
    "    self.d = d\n",
    "    self.hidden_sizes = hidden_size\n",
    "    self.ordering = np.arange(self.nin) if ordering is None else ordering\n",
    "    self.one_hot_input = one_hot_input\n",
    "\n",
    "    # define a simple MLP neural net\n",
    "    self.net = []\n",
    "    hs = [self.nin * d if one_hot_input else self.nin] + self.hidden_sizes + [self.nout]\n",
    "    for h0, h1 in zip(hs, hs[1:]):\n",
    "      self.net.extend([\n",
    "        MaskedLinear(h0, h1),\n",
    "        nn.ReLU(),\n",
    "      ])\n",
    "    self.net.pop()  # pop the last ReLU for the output layer\n",
    "    self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    self.m = {}\n",
    "    self.create_mask()  # builds the initial self.m connectivity\n",
    "\n",
    "  def create_mask(self):\n",
    "    L = len(self.hidden_sizes)\n",
    "\n",
    "    # sample the order of the inputs and the connectivity of all neurons\n",
    "    self.m[-1] = self.ordering\n",
    "    for l in range(L):\n",
    "      self.m[l] = np.random.randint(self.m[l - 1].min(), \n",
    "                                      self.nin - 1, size=self.hidden_sizes[l])\n",
    "\n",
    "    # construct the mask matrices\n",
    "    masks = [self.m[l - 1][:, None] <= self.m[l][None, :] for l in range(L)]\n",
    "    masks.append(self.m[L - 1][:, None] < self.m[-1][None, :])\n",
    "\n",
    "    masks[-1] = np.repeat(masks[-1], self.d, axis=1)\n",
    "    if self.one_hot_input:\n",
    "      masks[0] = np.repeat(masks[0], self.d, axis=0)\n",
    "\n",
    "    # set the masks in all MaskedLinear layers\n",
    "    layers = [l for l in self.net.modules() if isinstance(l, MaskedLinear)]\n",
    "    for l, m in zip(layers, masks):\n",
    "      l.set_mask(m)\n",
    "\n",
    "  def forward(self, x):\n",
    "    batch_size = x.shape[0]\n",
    "    if self.one_hot_input:\n",
    "      x = x.long().view(-1)\n",
    "      x = to_one_hot(x, self.d)\n",
    "      x = x.view(batch_size, -1)\n",
    "    else:\n",
    "      x = x.float()\n",
    "      x = x.view(batch_size, self.nin)\n",
    "    logits = self.net(x).view(batch_size, self.nin, self.d)\n",
    "    return logits.permute(0, 2, 1).contiguous().view(batch_size, self.d, *self.input_shape)\n",
    "\n",
    "  def loss(self, x):\n",
    "      return F.cross_entropy(self(x), x.long())\n",
    "\n",
    "  def sample(self, n):\n",
    "    samples = torch.zeros(n, self.nin).cuda()\n",
    "    with torch.no_grad():\n",
    "      for i in range(self.nin):\n",
    "        logits = self(samples).view(n, self.d, self.nin)[:, :, self.ordering[i]]\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        samples[:, self.ordering[i]] = torch.multinomial(probs, 1).squeeze(-1)\n",
    "      samples = samples.view(n, *self.input_shape)\n",
    "    return samples.cpu().numpy()\n",
    "\n",
    "  def get_distribution(self):\n",
    "    assert self.input_shape == (2,), 'Only available for 2D joint'\n",
    "    x = np.mgrid[0:self.d, 0:self.d].reshape(2, self.d ** 2).T\n",
    "    x = torch.LongTensor(x).cuda()\n",
    "    log_probs = F.log_softmax(self(x), dim=1)\n",
    "    distribution = torch.gather(log_probs, 1, x.unsqueeze(1)).squeeze(1)\n",
    "    distribution = distribution.sum(dim=1)\n",
    "    return distribution.exp().view(self.d, self.d).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dirname, dataset):\n",
    "    mnist_trainset = dataset(root=dirname, train=True, download=True, transform=None)\n",
    "    mnist_testset = dataset(root=dirname, train=False, download=True, transform=None)\n",
    "    train_data, test_data = mnist_trainset.data, mnist_testset.data\n",
    "    train_data = (train_data > 127).numpy().astype('uint8')\n",
    "    test_data = (test_data > 127).numpy().astype('uint8')\n",
    "    return np.transpose([train_data], (1, 0, 2, 3)), np.transpose([test_data], (1, 0, 2, 3))\n",
    "\n",
    "def load_mnist(dirname):\n",
    "    return load_dataset(dirname, datasets.MNIST)\n",
    "\n",
    "def load_fashionmnist(dirname):\n",
    "    return load_dataset(dirname, datasets.FashionMNIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch, grad_clip=None, quiet=False):\n",
    "  model.train()\n",
    "  \n",
    "  train_losses = []\n",
    "  for x in train_loader:\n",
    "    x = x.cuda().contiguous()\n",
    "    loss = model.loss(x)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    if grad_clip:\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "    optimizer.step()\n",
    "    train_losses.append(loss.item())\n",
    "  return train_losses\n",
    "\n",
    "def eval_loss(model, data_loader, quiet=False):\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for x in data_loader:\n",
    "      x = x.cuda().contiguous()\n",
    "      loss = model.loss(x)\n",
    "      total_loss += loss * x.shape[0]\n",
    "    avg_loss = total_loss / len(data_loader.dataset)\n",
    "\n",
    "  return avg_loss.item()\n",
    "\n",
    "def train_epochs(model, train_loader, test_loader, train_args, quiet=False):\n",
    "  epochs, lr = train_args['epochs'], train_args['lr']\n",
    "  grad_clip = train_args.get('grad_clip', None)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "  train_losses = []\n",
    "  test_losses = [eval_loss(model, test_loader)]\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_losses.extend(train(model, train_loader, optimizer, epoch, grad_clip))\n",
    "    test_loss = eval_loss(model, test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    if not quiet:\n",
    "      print(f'Epoch {epoch}, Test loss {test_loss:.4f}')\n",
    "\n",
    "  return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_mnist('data')\n",
    "train_data_f, test_data_f = load_fashionmnist('datafashion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, test_data, epochs=10, batch_size=128):\n",
    "    train_loader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = data.DataLoader(test_data, batch_size=batch_size)\n",
    "    train_losses, test_losses = train_epochs(model, train_loader, test_loader, \n",
    "                                       dict(epochs=epochs, lr=1e-3))\n",
    "    return model, train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MADE((1, 28, 28), 2, hidden_size=[512, 512]).cuda()\n",
    "model, train_losses, test_losses = train_model(model, train_data, test_data, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, test_losses):\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    n_epochs = len(test_losses) - 1\n",
    "    x_train = np.linspace(0, n_epochs, len(train_losses))\n",
    "    x_test = np.arange(n_epochs + 1)\n",
    "\n",
    "    ax.plot(x_train, train_losses, label='Ошибка на тренировочном множестве')\n",
    "    ax.plot(x_test, test_losses, label='Ошибка на тестовом множестве')\n",
    "    ax.legend()\n",
    "    plt.xlabel('Эпоха обучения')\n",
    "    plt.ylabel('Ошибка')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_grid(im_samples, nrows):\n",
    "    grid_img = make_grid(im_samples, nrow=nrows)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_samples = torch.FloatTensor(model.sample(49))\n",
    "plot_sample_grid(im_samples, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskConv2d(nn.Conv2d):\n",
    "  def __init__(self, mask_type, *args, conditional_size=None, \n",
    "               color_conditioning=False, **kwargs):\n",
    "    assert mask_type == 'A' or mask_type == 'B'\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.conditional_size = conditional_size\n",
    "    self.color_conditioning = color_conditioning\n",
    "    self.register_buffer('mask', torch.zeros_like(self.weight))\n",
    "    self.create_mask(mask_type)\n",
    "    if self.conditional_size:\n",
    "      if len(self.conditional_size) == 1:\n",
    "        self.cond_op = nn.Linear(conditional_size[0], self.out_channels)\n",
    "      else:\n",
    "        self.cond_op = nn.Conv2d(conditional_size[0], self.out_channels,\n",
    "                                 kernel_size=3, padding=1)\n",
    "\n",
    "  def forward(self, input, cond=None):\n",
    "    batch_size = input.shape[0]\n",
    "    out = F.conv2d(input, self.weight * self.mask, self.bias, self.stride,\n",
    "                   self.padding, self.dilation, self.groups)\n",
    "    if self.conditional_size:\n",
    "      if len(self.conditional_size) == 1:\n",
    "        # Broadcast across height and width of image and add as conditional bias\n",
    "        out = out + self.cond_op(cond).view(batch_size, -1, 1, 1)\n",
    "      else:\n",
    "        out = out + self.cond_op(cond)\n",
    "    return out\n",
    "\n",
    "  def create_mask(self, mask_type):\n",
    "    k = self.kernel_size[0]\n",
    "    self.mask[:, :, :k // 2] = 1\n",
    "    self.mask[:, :, k // 2, :k // 2] = 1\n",
    "    if self.color_conditioning:\n",
    "      assert self.in_channels % 3 == 0 and self.out_channels % 3 == 0\n",
    "      one_third_in, one_third_out = self.in_channels // 3, self.out_channels // 3\n",
    "      if mask_type == 'B':\n",
    "        self.mask[:one_third_out, :one_third_in, k // 2, k // 2] = 1\n",
    "        self.mask[one_third_out:2*one_third_out, :2*one_third_in, k // 2, k // 2] = 1\n",
    "        self.mask[2*one_third_out:, :, k // 2, k // 2] = 1\n",
    "      else:\n",
    "        self.mask[one_third_out:2*one_third_out, :one_third_in, k // 2, k // 2] = 1\n",
    "        self.mask[2*one_third_out:, :2*one_third_in, k // 2, k // 2] = 1\n",
    "    else:\n",
    "      if mask_type == 'B':\n",
    "        self.mask[:, :, k // 2, k // 2] = 1\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "  def __init__(self, in_channels, **kwargs):\n",
    "    super().__init__()\n",
    "    self.block = nn.ModuleList([\n",
    "        nn.ReLU(),\n",
    "        MaskConv2d('B', in_channels, in_channels // 2, 1, **kwargs),\n",
    "        nn.ReLU(),\n",
    "        MaskConv2d('B', in_channels // 2, in_channels // 2, 7, padding=3, **kwargs),\n",
    "        nn.ReLU(),\n",
    "        MaskConv2d('B', in_channels // 2, in_channels, 1, **kwargs)\n",
    "    ])\n",
    "\n",
    "  def forward(self, x, cond=None):\n",
    "    out = x\n",
    "    for layer in self.block:\n",
    "      if isinstance(layer, MaskConv2d):\n",
    "        out = layer(out, cond=cond)\n",
    "      else:\n",
    "        out = layer(out)\n",
    "    return out + x\n",
    "\n",
    "class LayerNorm(nn.LayerNorm):\n",
    "  def __init__(self, color_conditioning, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.color_conditioning = color_conditioning\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.permute(0, 2, 3, 1).contiguous()\n",
    "    x_shape = x.shape\n",
    "    if self.color_conditioning:\n",
    "      x = x.contiguous().view(*(x_shape[:-1] + (3, -1)))\n",
    "    x = super().forward(x)\n",
    "    if self.color_conditioning:\n",
    "      x = x.view(*x_shape)\n",
    "    return x.permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "class PixelCNN(nn.Module):\n",
    "  def __init__(self, input_shape, n_colors, n_filters=64,\n",
    "               kernel_size=7, n_layers=5, \n",
    "               conditional_size=None, use_resblock=False,\n",
    "               color_conditioning=False):\n",
    "    super().__init__()\n",
    "    assert n_layers >= 2\n",
    "    n_channels = input_shape[0]\n",
    "\n",
    "    kwargs = dict(conditional_size=conditional_size, \n",
    "                  color_conditioning=color_conditioning)\n",
    "    if use_resblock:\n",
    "      block_init = lambda: ResBlock(n_filters, **kwargs)\n",
    "    else:    \n",
    "      block_init = lambda: MaskConv2d('B', n_filters, n_filters, \n",
    "                                      kernel_size=kernel_size,\n",
    "                                      padding=kernel_size // 2, **kwargs)\n",
    "    \n",
    "    model = nn.ModuleList([MaskConv2d('A', n_channels, n_filters, \n",
    "                                      kernel_size=kernel_size,\n",
    "                                      padding=kernel_size // 2, **kwargs)])\n",
    "    for _ in range(n_layers):\n",
    "      if color_conditioning:\n",
    "        model.append(LayerNorm(color_conditioning, n_filters // 3))\n",
    "      else:\n",
    "        model.append(LayerNorm(color_conditioning, n_filters))\n",
    "      model.extend([nn.ReLU(), block_init()])\n",
    "    model.extend([nn.ReLU(), MaskConv2d('B', n_filters, n_filters, 1, **kwargs)])\n",
    "    model.extend([nn.ReLU(), MaskConv2d('B', n_filters, n_colors * n_channels, 1, **kwargs)])\n",
    "\n",
    "    if conditional_size:\n",
    "      if len(conditional_size) == 1:\n",
    "        self.cond_op = lambda x: x\n",
    "      else:\n",
    "        self.cond_op = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    self.net = model\n",
    "    self.input_shape = input_shape\n",
    "    self.n_colors = n_colors\n",
    "    self.n_channels = n_channels\n",
    "    self.color_conditioning = color_conditioning\n",
    "    self.conditional_size = conditional_size\n",
    "\n",
    "  def forward(self, x, cond=None):\n",
    "    batch_size = x.shape[0]\n",
    "    out = (x.float() / (self.n_colors - 1) - 0.5) / 0.5\n",
    "    if self.conditional_size:\n",
    "      cond = self.cond_op(cond)\n",
    "    for layer in self.net:\n",
    "      if isinstance(layer, MaskConv2d) or isinstance(layer, ResBlock):\n",
    "        out = layer(out, cond=cond)\n",
    "      else:\n",
    "        out = layer(out)\n",
    "\n",
    "    if self.color_conditioning:\n",
    "      return out.view(batch_size, self.n_channels, self.n_colors, \n",
    "                      *self.input_shape[1:]).permute(0, 2, 1, 3, 4)\n",
    "    else:\n",
    "      return out.view(batch_size, self.n_colors, *self.input_shape)\n",
    "\n",
    "  def loss(self, x, cond=None):\n",
    "    return F.cross_entropy(self(x, cond=cond), x.long())\n",
    "\n",
    "  def sample(self, n, cond=None):\n",
    "    samples = torch.zeros(n, *self.input_shape).cuda()\n",
    "    with torch.no_grad():\n",
    "      for r in range(self.input_shape[1]):\n",
    "        for c in range(self.input_shape[2]):\n",
    "          for k in range(self.n_channels):\n",
    "            logits = self(samples, cond=cond)[:, :, k, r, c]\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            samples[:, k, r, c] = torch.multinomial(probs, 1).squeeze(-1)\n",
    "    return samples.permute(0, 2, 3, 1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN((1, 28, 28), 2, n_layers=5).cuda()\n",
    "model_pixelcnn, train_losses_pixelcnn, test_losses_pixelcnn = train_model(model, train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses_pixelcnn, test_losses_pixelcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_samples_pixelcnn = torch.FloatTensor(model_pixelcnn.sample(49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_sample_grid(im_samples_pixelcnn.permute(0,3,1,2), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN((1, 28, 28), 2, n_layers=5).cuda()\n",
    "model_pixelcnn_f, train_losses_pixelcnn_f, test_losses_pixelcnn_f = train_model(model, train_data_f, test_data_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_samples_pixelcnn_f = torch.FloatTensor(model_pixelcnn_f.sample(49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample_grid(im_samples_pixelcnn_f.permute(0,3,1,2), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
